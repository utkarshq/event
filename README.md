# Vision Event Engine

A vision-first document extraction engine that uses AI to intelligently extract structured data from images and documents. Supports multiple AI providers including Google Gemini, OpenAI, and local Ollama models, as well as a fast local PaddleOCR mode.

## âœ¨ Features

- **Multi-Provider AI Support**: Google Gemini, OpenAI GPT-4V, local Ollama, and PaddleOCR
- **Three Extraction Strategies**:
  - **Strategy A**: Full Vision LLM (best accuracy, requires API key)
  - **Strategy B**: Hybrid Pipeline (PaddleOCR + LLM refinement)
  - **Strategy C**: Local OCR Only (fastest, no API required)
- **Streaming Responses**: Real-time token streaming with live progress display
- **Dynamic Schema**: Automatically adapts to extract any structured data
- **Dynamically Optimized for Apple Silicon**: Automatically detects M1/M2/M3 chips to use Metal Performance Shaders (MPS) for up to 5x faster inference.
- **Smart Tier Switching**: Automatically upgrades the OCR engine from "Eco" to "Lite" when VLM models are requested.
- **Modern Web UI**: Clean, responsive interface with dark mode
- **Headless Mode**: Full API access for backend integration
- **SQLite Storage**: Persistent event history with automatic schema evolution

## ğŸš€ Quick Start

### Using Docker (Recommended)

```bash
docker compose up --build
```

Open http://localhost:3000 in your browser.

### Manual Setup

Requires [Bun](https://bun.sh) runtime (v1.0+).

```bash
# Install dependencies
bun install

# Start in development mode (hot reload)
bun run dev

# Or start in production mode
bun run start
```

### First-Time Setup

The first startup will automatically:
1. Create a Python virtual environment
2. Install PaddleOCR dependencies
3. Download OCR models (~500MB)

This process takes 2-5 minutes on first run.

## ğŸ”§ Configuration

### Web Interface

1. Open http://localhost:3000
2. Click the **settings** icon in the sidebar
3. Select your provider (Gemini, OpenAI, or Ollama)
4. Enter your API key (if required)
5. Choose a model

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `PORT` | `3000` | HTTP server port |
| `SERVE_STATIC` | `true` | Enable/disable static file serving |
| `OLLAMA_HOST` | `http://localhost:11434` | Ollama server URL |

## ğŸ“¡ API Reference

All endpoints return JSON and accept CORS requests.

### Core Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/upload` | POST | Upload image/document (multipart/form-data) |
| `/api/parse-sync` | POST | Extract data with streaming response |
| `/api/events` | GET | List all saved extractions |
| `/api/health` | POST | Check provider connectivity |

### PaddleOCR Bridge Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/paddle/status` | GET | Get bridge status and tier info |
| `/api/paddle/tier` | POST | Switch active OCR tier |
| `/api/paddle/logs` | GET | Get bridge process logs |

See [INTEGRATION.md](./INTEGRATION.md) for detailed API documentation with examples.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Frontend (public/)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Upload UI  â”‚  â”‚  Config UI  â”‚  â”‚  History/Results    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                    â”‚
          â–¼                â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Bun HTTP Server (src/)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    Routes   â”‚  â”‚  Providers  â”‚  â”‚   Model Service     â”‚  â”‚
â”‚  â”‚  (api/)     â”‚â”€â”€â”‚  (Gemini,   â”‚  â”‚   (Bridge Mgmt)     â”‚  â”‚
â”‚  â”‚             â”‚  â”‚  OpenAI,    â”‚  â”‚                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  Paddle)    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜             â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚                    â”‚
                           â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        External AI APIs          â”‚  â”‚  PaddleOCR Bridge      â”‚
â”‚  (Gemini, OpenAI, Ollama)        â”‚  â”‚  (Python/FastAPI)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  Port 5000             â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
vision-event-engine/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ server.ts           # Main server entry point
â”‚   â”œâ”€â”€ db.ts               # SQLite database module
â”‚   â”œâ”€â”€ prompt.ts           # AI system prompt
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes.ts       # API route handlers
â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”œâ”€â”€ base.provider.ts    # Abstract provider class
â”‚   â”‚   â”œâ”€â”€ gemini.provider.ts  # Google Gemini
â”‚   â”‚   â”œâ”€â”€ openai.provider.ts  # OpenAI/Ollama
â”‚   â”‚   â””â”€â”€ paddle.provider.ts  # PaddleOCR bridge
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ model.service.ts    # Bridge lifecycle management
â”‚   â”‚   â””â”€â”€ provider.service.ts # Provider orchestration
â”‚   â”œâ”€â”€ bridge/
â”‚   â”‚   â””â”€â”€ paddle_bridge.py    # Python OCR server
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ ollama.ts           # Ollama utility functions
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ index.html          # Main HTML
â”‚   â”œâ”€â”€ script.js           # Frontend logic
â”‚   â”œâ”€â”€ style.css           # Main styles
â”‚   â””â”€â”€ tiers.css           # Tier selection styles
â”œâ”€â”€ data/                   # SQLite database (auto-created)
â”œâ”€â”€ .paddle_cache/          # OCR model cache (auto-created)
â”œâ”€â”€ Dockerfile              # Production container
â”œâ”€â”€ docker-compose.yml      # Container orchestration
â””â”€â”€ package.json            # Node dependencies
```

## ğŸ¤ Contributing

See [DEVELOPMENT.md](./DEVELOPMENT.md) for development setup and guidelines.

## ï¿½ï¸ Troubleshooting
- **Upload Hangs**: If uploads don't trigger processing, check for JS errors. The system now has a fallback for VRAM mode to send raw files if compression fails.
- **Paddle Bridge Defaults to Eco**: This is normal on startup. If you request a VLM model, the system will automatically restart the bridge in "Lite" mode.
- **Dependency Issues**: If you see `ImportError: No module named 'einops'`, run `pip install -r requirements.txt` again.

## ï¿½ğŸ“„ License

Proprietary - All rights reserved.
